{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0d94db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import'''\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import csv\n",
    "import datetime\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0ac095",
   "metadata": {},
   "source": [
    "### 메타데이터 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d39d742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 서울역 Seoul Station 37.55575305 126.9724563\n"
     ]
    }
   ],
   "source": [
    "# 전국 도시철도 역사정보 표준데이터\n",
    "meta_file = 'data\\metro-meta.csv'\n",
    "\n",
    "# csv 파일을 pandas dataframe 형식으로 읽어들인다\n",
    "meta_csv = pd.read_csv(meta_file)\n",
    "\n",
    "# 서울 도시철도 데이터만 필터링한다 ('노선명' 필드에 '서울 도시철도'가 포함된 행만 선택)\n",
    "meta_csv = meta_csv[meta_csv['노선명'].str.contains('서울 도시철도')]\n",
    "\n",
    "# 역 번호와 역사명 출력해보기\n",
    "#print(meta_csv.loc[:, ['역번호', '역사명']])\n",
    "\n",
    "# 전체 행 갯수 출력\n",
    "#print (\"[*] 전체 행 갯수: \", len(meta_csv))\n",
    "\n",
    "# 전체 행 출력\n",
    "#for idx in meta_csv.index: print(meta_csv.loc[idx])\n",
    "    \n",
    "# 역 코드를 key로 하여 해당 역의 메타데이터 접근 (서울역의 역번호는 150이므로, 해당 값을 이용하여 row 선택)\n",
    "test_obj = meta_csv[meta_csv['역번호']=='150']\n",
    "\n",
    "station_num = test_obj['역번호'].values[0]\n",
    "station_name = test_obj['역사명'].values[0]\n",
    "station_name_en = test_obj['영문역사명'].values[0]\n",
    "station_lat = test_obj['역위도'].values[0]\n",
    "station_lon = test_obj['역경도'].values[0]\n",
    "\n",
    "# 테스트 출력 (역번호, 역사명, 역사명-영문, 역위도, 역경도)\n",
    "print(station_num, station_name, station_name_en, station_lat, station_lon)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470abc94",
   "metadata": {},
   "source": [
    "### 입력 데이터파일 전처리 (raw + meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e60ce707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\seoul-metro-logs-raw-2018.csv\n",
      "10000  processed.\n",
      "20000  processed.\n",
      "30000  processed.\n",
      "40000  processed.\n",
      "50000  processed.\n",
      "60000  processed.\n",
      "70000  processed.\n",
      "80000  processed.\n",
      "90000  processed.\n",
      "100000  processed.\n",
      "110000  processed.\n",
      "120000  processed.\n",
      "130000  processed.\n",
      "140000  processed.\n",
      "150000  processed.\n",
      "160000  processed.\n",
      "170000  processed.\n",
      "180000  processed.\n",
      "190000  processed.\n",
      "200000  processed.\n",
      "data\\seoul-metro-logs-raw-2019.csv\n",
      "10000  processed.\n",
      "20000  processed.\n",
      "30000  processed.\n",
      "40000  processed.\n",
      "50000  processed.\n",
      "60000  processed.\n",
      "70000  processed.\n",
      "80000  processed.\n",
      "90000  processed.\n",
      "100000  processed.\n",
      "110000  processed.\n",
      "120000  processed.\n",
      "130000  processed.\n",
      "140000  processed.\n",
      "150000  processed.\n",
      "160000  processed.\n",
      "170000  processed.\n",
      "180000  processed.\n",
      "190000  processed.\n",
      "200000  processed.\n",
      "data\\seoul-metro-logs-raw-2020.csv\n",
      "10000  processed.\n",
      "20000  processed.\n",
      "30000  processed.\n",
      "40000  processed.\n",
      "50000  processed.\n",
      "60000  processed.\n",
      "70000  processed.\n",
      "80000  processed.\n",
      "90000  processed.\n",
      "100000  processed.\n",
      "110000  processed.\n",
      "120000  processed.\n",
      "130000  processed.\n",
      "140000  processed.\n",
      "150000  processed.\n",
      "160000  processed.\n",
      "170000  processed.\n",
      "180000  processed.\n",
      "190000  processed.\n",
      "200000  processed.\n",
      "[*] process done.\n"
     ]
    }
   ],
   "source": [
    "DEBUG = False #True\n",
    "\n",
    "years = ['2018', '2019', '2020']\n",
    "#years = ['2020']\n",
    "# 입력파일명 정의\n",
    "raw_file_prefix = 'seoul-metro-logs-raw-'\n",
    "# 결과파일명 정의\n",
    "result_file_prefix = 'seoul-metro-logs2-'\n",
    "\n",
    "for year in years:\n",
    "    cur_file = os.path.join('data', raw_file_prefix + year + '.csv') \n",
    "    result_file = open(os.path.join('data', result_file_prefix+year+'.json'), 'w', encoding='utf-8')\n",
    "    \n",
    "    print(cur_file)\n",
    "    \n",
    "    f = open(cur_file, 'r')\n",
    "    rdr = csv.reader(f)\n",
    "    next(rdr) #Header 스킵\n",
    "    \n",
    "    num_line = 0\n",
    "    \n",
    "    dowEn = [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"]\n",
    "    dowKo = [\"월\", \"화\", \"수\", \"목\", \"금\", \"토\", \"일\"]\n",
    "    \n",
    "    for line in rdr:  \n",
    "        data = dict()\n",
    "        \n",
    "        # 현재 읽은 라인 (승차 데이터)\n",
    "        data_in = line\n",
    "        # 다음 라인 (하차 데이터)\n",
    "        data_out = next(rdr)\n",
    "        \n",
    "        cur_date = list(map(lambda x: int(x) , data_in[0].split('-')))\n",
    "        \n",
    "        line_num = data_in[1].replace('호선', '')\n",
    "        station_code = data_in[2]\n",
    "        \n",
    "        data['line_num'] = line_num\n",
    "        data['location'] = dict()\n",
    "        data['station'] = dict()\n",
    "        data['day_of_week'] = dict()\n",
    "        \n",
    "        meta_obj = meta_csv[meta_csv['역번호']==station_code]\n",
    "        \n",
    "        # 예외 처리\n",
    "        if meta_obj.empty: continue\n",
    "        \n",
    "        data['location']['lat'] = meta_obj['역위도'].values[0]\n",
    "        data['location']['lon'] = meta_obj['역경도'].values[0]\n",
    "        \n",
    "        data['station']['name'] = meta_obj['역사명'].values[0]\n",
    "        data['station']['en'] = meta_obj['영문역사명'].values[0]\n",
    "        data['station']['code'] = station_code\n",
    "        \n",
    "        ## 시간별로 \n",
    "        for h in range(19):\n",
    "            # 날짜시간 조합\n",
    "            \n",
    "            \n",
    "            _time = datetime.datetime(cur_date[0], cur_date[1], cur_date[2], h+5)\n",
    "            cur_time = _time.astimezone().isoformat() # 새벽 5시부터 시작\n",
    "            # 승하차 인원\n",
    "            people_in = int(data_in[h+5])\n",
    "            people_out = int(data_out[h+5])\n",
    "        \n",
    "            data['@timestamp'] = cur_time\n",
    "            data['hour_of_day'] = h+5\n",
    "            dow = _time.weekday()\n",
    "            data['day_of_week']['en'] = dowEn[dow]\n",
    "            data['day_of_week']['ko'] = dowKo[dow]\n",
    "            data['day_of_week']['no'] = dow\n",
    "\n",
    "            data['people'] = dict()\n",
    "            data['people']['in'] = people_in\n",
    "            data['people']['out'] = people_out\n",
    "            data['people']['total'] = people_in + people_out\n",
    "                        \n",
    "            #print(data)\n",
    "            # 파일로 출력\n",
    "            result_file.write(json.dumps(data, ensure_ascii=False))\n",
    "            result_file.write('\\n')\n",
    "            \n",
    "        # 현재까지 읽어들인 라인 갯수\n",
    "        num_line += 2\n",
    "        if num_line % 10000 == 0: \n",
    "            print(num_line, ' processed.')\n",
    "        \n",
    "        if(DEBUG): \n",
    "            if (num_line == 100): break\n",
    "            \n",
    "    result_file.close()\n",
    "        \n",
    "    f.close()  \n",
    "\n",
    "print ('[*] process done.')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6d2f30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
